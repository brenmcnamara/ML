{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the Gaussian Curve\n",
    "\n",
    "In the notebook implementing the basic back propagation algorithm from scratch, I used as an example case of learning a gaussian curve. In theory, our model should be able to learn this well since there is no noise in the model (we are learning a deterministic function).\n",
    "\n",
    "I will explore more robust approaches in deep learning to properly learn this gaussian curve. Some ideas I will try:\n",
    "\n",
    "- Use more data\n",
    "- Hyper-Parameter Testing\n",
    "  - Number and Shape of Layers in the Network\n",
    "  - Learning Rate\n",
    "- Better Training Procedure: will use the Adam Algorithm instead of SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Gaussian Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_curve(mean, variance, delta=0.2):\n",
    "    std = math.sqrt(variance)\n",
    "    normalize = 1 / (std * math.sqrt(2 * 3.14159))\n",
    "\n",
    "    def gaussian_curve(x, y):\n",
    "        term = (x - mean) / std\n",
    "        expected = normalize * np.exp(-1/2 * term * term)\n",
    "        return 1 if abs(expected - y) <= delta else 0\n",
    "    \n",
    "    return gaussian_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_func = create_gaussian_curve(0.0, 0.05)\n",
    "points = np.random.rand(2, num_points) * 4 - 2\n",
    "labels = np.apply_along_axis(lambda x: gauss_func(x[0], x[1]), axis=0, arr=points)\n",
    "\n",
    "random_assignment = np.random.rand(num_points)\n",
    "train_mask = random_assignment <= 0.8\n",
    "valid_mask = (random_assignment > 0.8) & (random_assignment <= 0.9)\n",
    "test_mask = random_assignment > 0.9\n",
    "\n",
    "train_data = points[:, train_mask]\n",
    "train_labels = labels[train_mask]\n",
    "\n",
    "valid_data = points[:, valid_mask]\n",
    "valid_labels = labels[valid_mask]\n",
    "\n",
    "test_data = points[:, test_mask]\n",
    "test_labels = labels[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's make a plot to see where the curve is being drawn.\n",
    "# We will look at the first 5,000 points.\n",
    "\n",
    "for i in range(5000):\n",
    "    point = train_data[:, i]\n",
    "    label = train_labels[i]\n",
    "    plt.plot(point[0], point[1], 'go' if label == 1 else 'ro')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    mask = X >= 0\n",
    "    return X * mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_deriv(X):\n",
    "    return (X >= 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1. / (1 + np.exp(-X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_deriv(X):\n",
    "    sig = sigmoid(X)\n",
    "    return sig * (1 - sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss(output, expected):\n",
    "    # Note that this function will throw errors if any of the output\n",
    "    # values are 0 or 1 exactly.\n",
    "    m = output.shape[1]\n",
    "\n",
    "    # Offset the output if there are any values exactly equal to\n",
    "    # zero or one to avoid log(0).\n",
    "    zero_correct = (output == 0).astype(float) * 1e-10 \n",
    "    one_correct = (output == 1).astype(float) * (-1e-10)\n",
    "    output = output + zero_correct + one_correct\n",
    "\n",
    "    return np.sum((expected * -np.log(output)) + (1 - expected) * -np.log(1 - output)) / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss_grad(output, expected):\n",
    "    # Note that this function will throw errors if any output is 0.\n",
    "    m = output.shape[1]\n",
    "    return (1. / m) * ((expected / output) - (1 - expected) / (1 - output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: When initializing the layers, we will assume that the output\n",
    "# layer is always a single output through a sigmoid activation.\n",
    "def xavier_initialization(input_size, layer_sizes):\n",
    "    layers = []\n",
    "    \n",
    "    prev_layer_size = input_size\n",
    "\n",
    "    for size in layer_sizes:\n",
    "        normalize = 1. / math.sqrt(prev_layer_size)\n",
    "        weights = np.random.randn(size, prev_layer_size) * normalize\n",
    "        biases = np.random.randn(size, 1) * normalize\n",
    "        layers.append((weights, biases))\n",
    "\n",
    "        prev_layer_size = size\n",
    "        \n",
    "    # Add a final output layer for sigmoid activation.\n",
    "    weights = np.random.randn(1, prev_layer_size)\n",
    "    biases = np.random.randn(1, 1)\n",
    "    layers.append((weights, biases))\n",
    "    \n",
    "    return layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, X):\n",
    "    Y = X\n",
    "\n",
    "    linear_outputs = []\n",
    "    outputs = []\n",
    "\n",
    "    for (i, (weights, biases)) in enumerate(model['layers'][0:-1]):\n",
    "        Y = np.dot(weights, Y) + biases\n",
    "        linear_outputs.append(Y)\n",
    "\n",
    "        Y = relu(Y)\n",
    "        outputs.append(Y)\n",
    "        \n",
    "\n",
    "    # Note: Last layer is processed by sigmoid activation.\n",
    "    weights, biases = model['layers'][-1]\n",
    "\n",
    "    Y = np.dot(weights, Y) + biases\n",
    "    linear_outputs.append(Y)\n",
    "\n",
    "    Y = sigmoid(Y)\n",
    "    outputs.append(Y)\n",
    "\n",
    "    # Save the results of the forward pass so we can do a backward\n",
    "    # pass on them later.\n",
    "    if 'no_grad_check' not in model or not model['no_grad_check']:\n",
    "        model['linear_outputs'] = linear_outputs\n",
    "        model['input'] = X\n",
    "        model['outputs'] = outputs\n",
    "        model['result'] = Y\n",
    "\n",
    "    return Y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(model, expected):\n",
    "    # Note: We are assuming the model has already gone through a\n",
    "    # forward pass.\n",
    "\n",
    "    layers = model['layers']\n",
    "    linear_outputs = model['linear_outputs']\n",
    "    outputs = model['outputs']\n",
    "    X = model['input']\n",
    "    result = model['result']\n",
    "\n",
    "    L = len(layers)\n",
    "    m = result.shape[1] # Number of samples.\n",
    "\n",
    "    # Note: We can have multiple samples in the outputs, so we\n",
    "    # will end up with a gradient per sample.\n",
    "    output_prev_layer = X if len(outputs) <= 1 else outputs[-2]\n",
    "    loss_grad = binary_cross_entropy_loss_grad(result, expected)\n",
    "    error_last_layer = loss_grad * sigmoid_deriv(linear_outputs[-1])\n",
    "    bias_grad_last_layer = np.sum(error_last_layer, axis=1).reshape(-1, 1)\n",
    "    weights_grad_last_layer = np.dot(error_last_layer, output_prev_layer.T) # outer product\n",
    "    grad_last_layer = (weights_grad_last_layer, bias_grad_last_layer)\n",
    "\n",
    "    errors = [error_last_layer]\n",
    "    grads = [grad_last_layer]\n",
    "    \n",
    "    # Enumerate layers in reverse order to compute errors\n",
    "    # and gradients.\n",
    "    for i in range(L - 2, -1, -1):\n",
    "        linear_output = linear_outputs[i]\n",
    "        output_prev_layer = X if i == 0 else outputs[i-1]\n",
    "        error_next_layer = errors[-1]\n",
    "        weights_next_layer, bias_next_layer = layers[i+1]\n",
    "\n",
    "        error = np.dot(weights_next_layer.T, error_next_layer) * sigmoid_deriv(linear_output)\n",
    "        bias_grad = np.sum(error, axis=1).reshape(-1, 1)\n",
    "        weights_grad = np.dot(error, output_prev_layer.T)\n",
    "        \n",
    "        errors.append(error)\n",
    "        grads.append((weights_grad, bias_grad))\n",
    "        \n",
    "    # Reverse the order of errors and gradients so they go from\n",
    "    # first layer to last.\n",
    "    errors.reverse()\n",
    "    grads.reverse()\n",
    "    \n",
    "    if 'no_grad_check' not in model or not model['no_grad_check']:\n",
    "        model['errors'] = errors\n",
    "        model['grads'] = grads\n",
    "    \n",
    "    return grads, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_clipping(model, threshold=1.0):\n",
    "    \"\"\"\n",
    "    Returns True if the gradient was clipped, False otherwise.\n",
    "    \"\"\"\n",
    "    l2_norm = 0\n",
    "\n",
    "    for grad in model['grads']:\n",
    "        grad_weight, grad_bias = grad\n",
    "        l2_norm += np.sum(grad_weight * grad_weight)\n",
    "        l2_norm += np.sum(grad_bias * grad_bias)\n",
    "        \n",
    "    l2_norm = math.sqrt(l2_norm)\n",
    "\n",
    "    if l2_norm <= threshold:\n",
    "        return False\n",
    "\n",
    "    for (i, grad) in enumerate(model['grads']):\n",
    "        grad_weight, grad_bias = grad\n",
    "\n",
    "        grad_weight = grad_weight * threshold / l2_norm\n",
    "        grad_bias = grad_bias * threshold / l2_norm\n",
    "\n",
    "        model['grads'][i] = (grad_weight, grad_bias)\n",
    "        \n",
    "    return True\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_grad_check(model):\n",
    "    model['no_grad_check'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check(model):\n",
    "    model['no_grad_check'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_SGD(model, lr=0.1):\n",
    "    # Note: We are assuming the model has already gone\n",
    "    # through back propagation and all the gradients have\n",
    "    # been calculated.\n",
    "    \n",
    "    new_layers = []\n",
    "\n",
    "    for (i, layer) in enumerate(model['layers']):\n",
    "        weight, bias = layer\n",
    "        grad_weight, grad_bias = model['grads'][i]\n",
    "        \n",
    "        weight = weight + (lr * grad_weight)\n",
    "        bias = bias + (lr * grad_bias)\n",
    "\n",
    "        model['layers'][i] = (weight, bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_Adam(model):\n",
    "    # We keep track of exponential moving averages of our\n",
    "    # Adam optimization algorithm, cached in the model.\n",
    "    # If we are starting to train from scratch, we need\n",
    "    # to know to set these averages to 0.\n",
    "    mt = []\n",
    "    vt = []\n",
    "\n",
    "    for (i, layers) in enumerate(model['layers']):\n",
    "        weight, bias = layers\n",
    "        mt.append((np.zeros_like(weight), np.zeros_like(bias)))\n",
    "        vt.append((np.zeros_like(weight), np.zeros_like(bias)))\n",
    "        \n",
    "    model['mt'] = mt\n",
    "    model['vt'] = vt\n",
    "    model['t'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_Adam(model, lr, beta_1=0.9, beta_2=0.999, epsilon=1e-10):\n",
    "    # Note: We are assuming the model has already gone through\n",
    "    # back propagation and all the gradients have been calculated.\n",
    "    \n",
    "    t = model['t'] + 1\n",
    "\n",
    "    one_minus_beta_1 = 1 - beta_1\n",
    "    one_minus_beta_2 = 1 - beta_2\n",
    "\n",
    "    one_minus_beta_1t = 1 - math.pow(beta_1, t)\n",
    "    one_minus_beta_2t = 1 - math.pow(beta_2, t)\n",
    "    \n",
    "    for (i, layer) in enumerate(model['layers']):\n",
    "        weight, bias = layer\n",
    "        grad_weight, grad_bias = model['grads'][i]\n",
    "\n",
    "        mt_minus_1_weight, mt_minus_1_bias = model['mt'][i]\n",
    "        vt_minus_1_weight, vt_minus_1_bias = model['vt'][i]\n",
    "        \n",
    "        # Calculating exponentially moving averages.\n",
    "        mt_weight = beta_1 * mt_minus_1_weight + one_minus_beta_1 * grad_weight\n",
    "        mt_bias = beta_1 * mt_minus_1_bias + one_minus_beta_1 * grad_bias\n",
    "        \n",
    "        vt_weight = beta_2 * vt_minus_1_weight + one_minus_beta_2 * grad_weight * grad_weight\n",
    "        vt_bias = beta_2 * vt_minus_1_bias + one_minus_beta_2 * grad_bias * grad_bias\n",
    "\n",
    "        # Bias correction of our moving averages.\n",
    "        mt_hat_weight = mt_weight / one_minus_beta_1t\n",
    "        mt_hat_bias = mt_bias / one_minus_beta_1t\n",
    "        vt_hat_weight = vt_weight / one_minus_beta_2t\n",
    "        vt_hat_bias = vt_bias / one_minus_beta_2t\n",
    "\n",
    "        # Calculate change in weights.\n",
    "        deltat_weight = mt_hat_weight / (np.sqrt(vt_hat_weight) + epsilon)\n",
    "        deltat_bias = mt_hat_bias / (np.sqrt(vt_hat_bias) + epsilon)\n",
    "        \n",
    "        # Update weights.\n",
    "        weight = weight + (lr * deltat_weight)\n",
    "        bias = bias + (lr * deltat_bias)\n",
    "\n",
    "        # Write to model.\n",
    "        model['layers'][i] = (weight, bias)\n",
    "        model['mt'][i] = (mt_weight, mt_bias)\n",
    "        model['vt'][i] = (vt_weight, vt_bias)\n",
    "\n",
    "    \n",
    "    model['t'] = t\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.logspace(-3, -8, num=6)\n",
    "\n",
    "layer_sizes_list = [\n",
    "    [30, 15],\n",
    "    [40, 16],\n",
    "    [20, 8, 3],\n",
    "    [35, 20, 4],\n",
    "    [40, 20, 10],\n",
    "    [50, 30, 8],\n",
    "    [60, 40, 15, 4],\n",
    "    [50, 30, 15, 8],\n",
    "]\n",
    "\n",
    "batch_sizes = [int(b) for b in np.logspace(2, 4, num=3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently have 144 unique combinations of hyper parameters, which is too much to test in a reasonable amount of time. We will randomly sample 15 of those 144 hyper parameter settings to try out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that it is possible we could end up testing the same hyper parameter settings\n",
    "# multiple times. We won't correct for this.\n",
    "\n",
    "hyperparams = []\n",
    "\n",
    "for i in range(15):\n",
    "    lr = learning_rates[int(math.floor(len(learning_rates) * random()))]\n",
    "    layer_sizes = layer_sizes_list[int(math.floor(len(layer_sizes_list) * random()))]\n",
    "    batch_size = batch_sizes[int(math.floor(len(batch_sizes) * random()))]\n",
    "\n",
    "    hyperparams.append({'lr': lr, 'layer_sizes': layer_sizes, 'batch_size': batch_size})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layer_sizes):\n",
    "    model = { 'layers': xavier_initialization(2, layer_sizes) }\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, lr, batch_size, epochs=1000, logs=True):\n",
    "\n",
    "    m = train_data.shape[1]\n",
    "\n",
    "    train_errors = []\n",
    "\n",
    "    reset_Adam(model)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for (batch_i, batch_start) in enumerate(range(0, m, batch_size)):\n",
    "            batch_X = train_data[:, batch_start:min(m, batch_start+batch_size)]\n",
    "            batch_Y = train_labels[batch_start:min(m, batch_start+batch_size)]\n",
    "\n",
    "            forward(model, batch_X)\n",
    "            backward(model, batch_Y)\n",
    "            gradient_clipping(model)\n",
    "            # step_Adam(model, lr=lr)\n",
    "            step_SGD(model, lr=lr)\n",
    "\n",
    "        if logs and i % 10 == 0:\n",
    "            # Turn off gradient checking while we calculate training\n",
    "            # and test loss.\n",
    "            no_grad_check(model)\n",
    "\n",
    "            train_output = forward(model, train_data)\n",
    "            train_error = binary_cross_entropy_loss(train_output, train_labels)\n",
    "            train_errors.append(train_error)\n",
    "\n",
    "            print(f'Train Error {train_error}')\n",
    "            \n",
    "            l2_norm = 0\n",
    "            max_grad = 0\n",
    "            min_grad = float('inf')\n",
    "\n",
    "            for grad in model['grads']:\n",
    "                weight, bias = grad\n",
    "                l2_norm += np.sum(weight * weight)\n",
    "                l2_norm += np.sum(bias * bias)\n",
    "\n",
    "                max_grad = max(max_grad, np.amax(np.abs(weight)))\n",
    "                min_grad = min(min_grad, np.amin(np.abs(weight)))\n",
    "\n",
    "            l2_norm = math.sqrt(l2_norm)\n",
    "\n",
    "            # Checking the overall squared gradient magnitude to look for\n",
    "            # any issues with vanishing / exploding gradients.\n",
    "            print(f'Grad Mag={l2_norm}, Grad Min={min_grad}, Grad Max={max_grad}')\n",
    "            \n",
    "            # Turn gradient checking back on before we start a new epoch.\n",
    "            grad_check(model)\n",
    "\n",
    "    if logs:\n",
    "        return train_errors\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 / 15\n",
      "lr=1e-05, layer_sizes=[35, 20, 4], batch_size=1000\n",
      "Train Error 0.4002513240218131\n",
      "Grad Mag=0.2898771791206006, Grad Min=0.0, Grad Max=0.12668860372221072\n",
      "Train Error 0.2873642580705218\n",
      "Grad Mag=0.030577408699684703, Grad Min=0.0, Grad Max=0.01015138797011766\n",
      "Train Error 0.2604740947239473\n",
      "Grad Mag=0.029299412520015725, Grad Min=0.0, Grad Max=0.013337477950637697\n",
      "Train Error 0.2490196072648569\n",
      "Grad Mag=0.026383901761583877, Grad Min=0.0, Grad Max=0.011942061667782111\n",
      "Train Error 0.24245462670493687\n",
      "Grad Mag=0.02409263814278206, Grad Min=0.0, Grad Max=0.008738386353741946\n",
      "Train Error 0.2479989802143635\n",
      "Grad Mag=0.028770543272600507, Grad Min=0.0, Grad Max=0.013370167825048539\n",
      "Train Error 0.2617284403288652\n",
      "Grad Mag=0.047843742544023016, Grad Min=3.729253487283765e-09, Grad Max=0.03233048365125627\n",
      "Train Error 0.2591195546479295\n",
      "Grad Mag=0.0749760920142504, Grad Min=4.0767845583238717e-10, Grad Max=0.057650011627393735\n",
      "Train Error 0.24545916406909288\n",
      "Grad Mag=0.10704348756256102, Grad Min=7.344246153464978e-11, Grad Max=0.08698999852453868\n",
      "Train Error 0.20814971112635997\n",
      "Grad Mag=0.15052555178701876, Grad Min=8.703911783759539e-12, Grad Max=0.12314920866591111\n",
      "Train Error 0.1572416774639002\n",
      "Grad Mag=0.0299290624626235, Grad Min=4.540484036806814e-12, Grad Max=0.011110415618559508\n",
      "Train Error 0.15026466859314128\n",
      "Grad Mag=0.35259970892462134, Grad Min=5.895540968594767e-13, Grad Max=0.2849653592151273\n",
      "Train Error 0.17005087805210628\n",
      "Grad Mag=1.0, Grad Min=3.5179907895291313e-13, Grad Max=0.7724281257054252\n",
      "Train Error 0.16742928665096862\n",
      "Grad Mag=0.9999999999999999, Grad Min=1.1900323657811542e-12, Grad Max=0.7433658207034445\n",
      "Train Error 0.13147772248400247\n",
      "Grad Mag=0.9415376190661522, Grad Min=5.827955031055939e-12, Grad Max=0.6738791414261036\n",
      "Train Error 0.12122119940896295\n",
      "Grad Mag=0.48756144808967744, Grad Min=2.3557847378710307e-12, Grad Max=0.33587672887513653\n",
      "Train Error 0.12498525018722423\n",
      "Grad Mag=0.5078852964321575, Grad Min=1.1108593875522544e-12, Grad Max=0.33743502376447665\n",
      "Train Error 0.13258937427299997\n",
      "Grad Mag=0.6586089655012362, Grad Min=6.128254268724789e-13, Grad Max=0.4206262550523583\n",
      "Train Error 0.1402466842743843\n",
      "Grad Mag=0.9559560920198447, Grad Min=2.2306566018940556e-13, Grad Max=0.5804005917941717\n",
      "Train Error 0.14924460259284855\n",
      "Grad Mag=1.0, Grad Min=3.2640908561286627e-14, Grad Max=0.5701468878478724\n",
      "Train Error 0.1559984831981522\n",
      "Grad Mag=1.0, Grad Min=4.950944097253847e-15, Grad Max=0.529816019472832\n",
      "Train Error 0.1581137459066273\n",
      "Grad Mag=1.0, Grad Min=6.736509718750064e-16, Grad Max=0.5273322968605966\n",
      "Train Error 0.17017982147712146\n",
      "Grad Mag=0.6582794527093885, Grad Min=8.967637109759184e-17, Grad Max=0.36782214738718594\n",
      "Train Error 0.19536187323005816\n",
      "Grad Mag=0.33829294412614225, Grad Min=2.2105592989852638e-18, Grad Max=0.20329185993297344\n",
      "Train Error 0.24030994165652597\n",
      "Grad Mag=0.04367179563736051, Grad Min=4.0972050178103475e-18, Grad Max=0.03324120571993207\n",
      "Train Error 0.3262781791528266\n",
      "Grad Mag=0.4019872929162033, Grad Min=4.424751027926695e-19, Grad Max=0.24579283213261988\n",
      "Train Error 0.46313033676343884\n",
      "Grad Mag=0.576244413722247, Grad Min=5.302305535465951e-19, Grad Max=0.37287704645379993\n",
      "Train Error 0.6103065741628552\n",
      "Grad Mag=0.6182846503830078, Grad Min=1.798586848202635e-19, Grad Max=0.4315316900940046\n",
      "Train Error 0.6606943463257701\n",
      "Grad Mag=0.5988108306326065, Grad Min=7.697287795446972e-19, Grad Max=0.440440771339139\n",
      "Train Error 0.6479059389123424\n",
      "Grad Mag=0.5421244452411899, Grad Min=8.372132848931942e-19, Grad Max=0.41941286779841236\n",
      "Train Error 0.6165867862143424\n",
      "Grad Mag=0.46058916905617764, Grad Min=5.166038720777619e-19, Grad Max=0.3755023596886855\n",
      "Train Error 0.553563273962042\n",
      "Grad Mag=0.3592810362925576, Grad Min=2.433707774124802e-19, Grad Max=0.3112692931712843\n",
      "Train Error 0.5068336471053956\n",
      "Grad Mag=0.2477584689305754, Grad Min=1.2469745700600613e-19, Grad Max=0.2330611586010984\n",
      "Train Error 0.4959041373362042\n",
      "Grad Mag=0.26641811129173876, Grad Min=6.767051902576235e-20, Grad Max=0.2523118582133987\n",
      "Train Error 0.4375253353357082\n",
      "Grad Mag=0.27254545698021937, Grad Min=4.2526052670761857e-20, Grad Max=0.2555837387434273\n",
      "Train Error 0.36704486746349785\n",
      "Grad Mag=0.40555733066451277, Grad Min=8.597429737996725e-20, Grad Max=0.27439479084863533\n",
      "Train Error 0.41695677648290436\n",
      "Grad Mag=0.9999999999999999, Grad Min=2.4790012634204315e-20, Grad Max=0.7534354301297727\n",
      "Train Error 0.5983645369872597\n",
      "Grad Mag=1.0, Grad Min=2.917741437358599e-21, Grad Max=0.7373713565413791\n",
      "Train Error 1.4174577065996643\n",
      "Grad Mag=1.0, Grad Min=3.3669025893514537e-21, Grad Max=0.7079384538526665\n",
      "Train Error 3.362769727548993\n",
      "Grad Mag=0.9999999999999999, Grad Min=1.1234997582649312e-21, Grad Max=0.6564915823640238\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-8b9d89c87261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layer_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-216-3292178a1db1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, train_labels, lr, batch_size, epochs, logs)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mgradient_clipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-a6445f3f9217>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlinear_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "valid_errors = []\n",
    "train_times = []\n",
    "\n",
    "data = train_data\n",
    "labels = train_labels\n",
    "\n",
    "# t_hyperparams = [{\n",
    "#     'layer_sizes': [4, 4, 3],\n",
    "#     'batch_size': 1000,\n",
    "#     'lr': 0.00001,\n",
    "# }]\n",
    "\n",
    "# For each set of hyper parameters, create and train a new model.\n",
    "# Record the trained model with the corresponding validation error.\n",
    "for (i, hyperparam) in enumerate(hyperparams):\n",
    "    print(f'Training model {i + 1} / {len(hyperparams)}')\n",
    "    print(f'lr={hyperparam[\"lr\"]}, layer_sizes={hyperparam[\"layer_sizes\"]}, batch_size={hyperparam[\"batch_size\"]}')\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    model = create_model(hyperparam['layer_sizes'])\n",
    "\n",
    "    train_model(model, data, labels, lr=hyperparam['lr'], batch_size=hyperparam['batch_size'])\n",
    "\n",
    "    no_grad(model)\n",
    "\n",
    "    valid_output = forward(model, valid_data)\n",
    "    valid_error = binary_cross_entropy_loss(valid_output, valid_labels)\n",
    "\n",
    "    grad(model)\n",
    "    \n",
    "    models.append(model)\n",
    "    valid_errors.append(valid_error)\n",
    "\n",
    "    end_time = time()\n",
    "\n",
    "    print(f'Model took {(end_time - start_time) / 60:0.2f}m to train.')\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
