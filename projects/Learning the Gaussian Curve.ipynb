{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the Gaussian Curve\n",
    "\n",
    "In the notebook implementing the basic back propagation algorithm from scratch, I used as an example case of learning a gaussian curve. In theory, our model should be able to learn this well since there is no noise in the model (we are learning a deterministic function).\n",
    "\n",
    "I will explore more robust approaches in deep learning to properly learn this gaussian curve. Some ideas I will try:\n",
    "\n",
    "- Use more data\n",
    "- Hyper-Parameter Testing\n",
    "  - Number and Shape of Layers in the Network\n",
    "  - Learning Rate\n",
    "- Better Training Procedure: will use the Adam Algorithm instead of SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Gaussian Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_curve(mean, variance, delta=0.2):\n",
    "    std = math.sqrt(variance)\n",
    "    normalize = 1 / (std * math.sqrt(2 * 3.14159))\n",
    "\n",
    "    def gaussian_curve(x, y):\n",
    "        term = (x - mean) / std\n",
    "        expected = normalize * np.exp(-1/2 * term * term)\n",
    "        return 1 if abs(expected - y) <= delta else 0\n",
    "    \n",
    "    return gaussian_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_func = create_gaussian_curve(0.0, 0.05)\n",
    "points = np.random.rand(2, num_points) * 4 - 2\n",
    "labels = np.apply_along_axis(lambda x: gauss_func(x[0], x[1]), axis=0, arr=points)\n",
    "\n",
    "random_assignment = np.random.rand(num_points)\n",
    "train_mask = random_assignment <= 0.8\n",
    "valid_mask = (random_assignment > 0.8) & (random_assignment <= 0.9)\n",
    "test_mask = random_assignment > 0.9\n",
    "\n",
    "train_data = points[:, train_mask]\n",
    "train_labels = labels[train_mask]\n",
    "\n",
    "valid_data = points[:, valid_mask]\n",
    "valid_labels = labels[valid_mask]\n",
    "\n",
    "test_data = points[:, test_mask]\n",
    "test_labels = labels[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's make a plot to see where the curve is being drawn.\n",
    "# We will look at the first 5,000 points.\n",
    "\n",
    "for i in range(5000):\n",
    "    point = train_data[:, i]\n",
    "    label = train_labels[i]\n",
    "    plt.plot(point[0], point[1], 'go' if label == 1 else 'ro')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    mask = X >= 0\n",
    "    return X * mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_deriv(X):\n",
    "    return (X >= 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1. / (1 + np.exp(-X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_deriv(X):\n",
    "    sig = sigmoid(X)\n",
    "    return sig * (1 - sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss(output, expected):\n",
    "    # Note that this function will throw errors if any of the output\n",
    "    # values are 0 or 1 exactly.\n",
    "    m = output.shape[1]\n",
    "\n",
    "    # Offset the output if there are any values exactly equal to\n",
    "    # zero or one to avoid log(0).\n",
    "    zero_correct = (output == 0).astype(float) * 1e-10 \n",
    "    one_correct = (output == 1).astype(float) * (-1e-10)\n",
    "    output = output + zero_correct + one_correct\n",
    "\n",
    "    return np.sum((expected * -np.log(output)) + (1 - expected) * -np.log(1 - output)) / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss_grad(output, expected):\n",
    "    # Note that this function will throw errors if any output is 0.\n",
    "    m = output.shape[1]\n",
    "    return (1. / m) * ((expected / output) - (1 - expected) / (1 - output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: When initializing the layers, we will assume that the output\n",
    "# layer is always a single output through a sigmoid activation.\n",
    "def xavier_initialization(input_size, layer_sizes):\n",
    "    layers = []\n",
    "    \n",
    "    prev_layer_size = input_size\n",
    "\n",
    "    for size in layer_sizes:\n",
    "        normalize = 1. / math.sqrt(prev_layer_size)\n",
    "        weights = np.random.randn(size, prev_layer_size) * normalize\n",
    "        biases = np.random.randn(size, 1) * normalize\n",
    "        layers.append((weights, biases))\n",
    "\n",
    "        prev_layer_size = size\n",
    "        \n",
    "    # Add a final output layer for sigmoid activation.\n",
    "    weights = np.random.randn(1, prev_layer_size)\n",
    "    biases = np.random.randn(1, 1)\n",
    "    layers.append((weights, biases))\n",
    "    \n",
    "    return layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, X):\n",
    "    Y = X\n",
    "\n",
    "    linear_outputs = []\n",
    "    outputs = []\n",
    "\n",
    "    for (i, (weights, biases)) in enumerate(model['layers'][0:-1]):\n",
    "        Y = np.dot(weights, Y) + biases\n",
    "        linear_outputs.append(Y)\n",
    "\n",
    "        Y = relu(Y)\n",
    "        outputs.append(Y)\n",
    "        \n",
    "\n",
    "    # Note: Last layer is processed by sigmoid activation.\n",
    "    weights, biases = model['layers'][-1]\n",
    "\n",
    "    Y = np.dot(weights, Y) + biases\n",
    "    linear_outputs.append(Y)\n",
    "\n",
    "    Y = sigmoid(Y)\n",
    "    outputs.append(Y)\n",
    "\n",
    "    # Save the results of the forward pass so we can do a backward\n",
    "    # pass on them later.\n",
    "    if 'no_grad_check' not in model or not model['no_grad_check']:\n",
    "        model['linear_outputs'] = linear_outputs\n",
    "        model['input'] = X\n",
    "        model['outputs'] = outputs\n",
    "        model['result'] = Y\n",
    "\n",
    "    return Y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(model, expected):\n",
    "    # Note: We are assuming the model has already gone through a\n",
    "    # forward pass.\n",
    "\n",
    "    layers = model['layers']\n",
    "    linear_outputs = model['linear_outputs']\n",
    "    outputs = model['outputs']\n",
    "    X = model['input']\n",
    "    result = model['result']\n",
    "\n",
    "    L = len(layers)\n",
    "    m = result.shape[1] # Number of samples.\n",
    "\n",
    "    # Note: We can have multiple samples in the outputs, so we\n",
    "    # will end up with a gradient per sample.\n",
    "    output_prev_layer = X if len(outputs) <= 1 else outputs[-2]\n",
    "    loss_grad = binary_cross_entropy_loss_grad(result, expected)\n",
    "    error_last_layer = loss_grad * sigmoid_deriv(linear_outputs[-1])\n",
    "    bias_grad_last_layer = np.sum(error_last_layer, axis=1).reshape(-1, 1)\n",
    "    weights_grad_last_layer = np.dot(error_last_layer, output_prev_layer.T) # outer product\n",
    "    grad_last_layer = (weights_grad_last_layer, bias_grad_last_layer)\n",
    "\n",
    "    errors = [error_last_layer]\n",
    "    grads = [grad_last_layer]\n",
    "    \n",
    "    # Enumerate layers in reverse order to compute errors\n",
    "    # and gradients.\n",
    "    for i in range(L - 2, -1, -1):\n",
    "        linear_output = linear_outputs[i]\n",
    "        output_prev_layer = X if i == 0 else outputs[i-1]\n",
    "        error_next_layer = errors[-1]\n",
    "        weights_next_layer, bias_next_layer = layers[i+1]\n",
    "\n",
    "        error = np.dot(weights_next_layer.T, error_next_layer) * sigmoid_deriv(linear_output)\n",
    "        bias_grad = np.sum(error, axis=1).reshape(-1, 1)\n",
    "        weights_grad = np.dot(error, output_prev_layer.T)\n",
    "        \n",
    "        errors.append(error)\n",
    "        grads.append((weights_grad, bias_grad))\n",
    "        \n",
    "    # Reverse the order of errors and gradients so they go from\n",
    "    # first layer to last.\n",
    "    errors.reverse()\n",
    "    grads.reverse()\n",
    "    \n",
    "    if 'no_grad_check' not in model or not model['no_grad_check']:\n",
    "        model['errors'] = errors\n",
    "        model['grads'] = grads\n",
    "    \n",
    "    return grads, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_clipping(model, threshold=1.0):\n",
    "    \"\"\"\n",
    "    Returns True if the gradient was clipped, False otherwise.\n",
    "    \"\"\"\n",
    "    l2_norm = 0\n",
    "\n",
    "    for grad in model['grads']:\n",
    "        grad_weight, grad_bias = grad\n",
    "        l2_norm += np.sum(grad_weight * grad_weight)\n",
    "        l2_norm += np.sum(grad_bias * grad_bias)\n",
    "        \n",
    "    l2_norm = math.sqrt(l2_norm)\n",
    "\n",
    "    if l2_norm <= threshold:\n",
    "        return False\n",
    "\n",
    "    for (i, grad) in enumerate(model['grads']):\n",
    "        grad_weight, grad_bias = grad\n",
    "\n",
    "        grad_weight = grad_weight * threshold / l2_norm\n",
    "        grad_bias = grad_bias * threshold / l2_norm\n",
    "\n",
    "        model['grads'][i] = (grad_weight, grad_bias)\n",
    "        \n",
    "    return True\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_grad_check(model):\n",
    "    model['no_grad_check'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check(model):\n",
    "    model['no_grad_check'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_SGD(model, lr=0.1):\n",
    "    # Note: We are assuming the model has already gone\n",
    "    # through back propagation and all the gradients have\n",
    "    # been calculated.\n",
    "    \n",
    "    new_layers = []\n",
    "\n",
    "    for (i, layer) in enumerate(model['layers']):\n",
    "        weight, bias = layer\n",
    "        grad_weight, grad_bias = model['grads'][i]\n",
    "        \n",
    "        weight = weight + (lr * grad_weight)\n",
    "        bias = bias + (lr * grad_bias)\n",
    "\n",
    "        model['layers'][i] = (weight, bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_Adam(model):\n",
    "    # We keep track of exponential moving averages of our\n",
    "    # Adam optimization algorithm, cached in the model.\n",
    "    # If we are starting to train from scratch, we need\n",
    "    # to know to set these averages to 0.\n",
    "    mt = []\n",
    "    vt = []\n",
    "\n",
    "    for (i, layers) in enumerate(model['layers']):\n",
    "        weight, bias = layers\n",
    "        mt.append((np.zeros_like(weight), np.zeros_like(bias)))\n",
    "        vt.append((np.zeros_like(weight), np.zeros_like(bias)))\n",
    "        \n",
    "    model['mt'] = mt\n",
    "    model['vt'] = vt\n",
    "    model['t'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_Adam(model, lr, beta_1=0.9, beta_2=0.999, epsilon=1e-20):\n",
    "    # Note: We are assuming the model has already gone through\n",
    "    # back propagation and all the gradients have been calculated.\n",
    "    \n",
    "    t = model['t'] + 1\n",
    "\n",
    "    one_minus_beta_1 = 1 - beta_1\n",
    "    one_minus_beta_2 = 1 - beta_2\n",
    "\n",
    "    one_minus_beta_1t = 1 - math.pow(beta_1, t)\n",
    "    one_minus_beta_2t = 1 - math.pow(beta_2, t)\n",
    "    \n",
    "    for (i, layer) in enumerate(model['layers']):\n",
    "        weight, bias = layer\n",
    "        grad_weight, grad_bias = model['grads'][i]\n",
    "\n",
    "        mt_minus_1_weight, mt_minus_1_bias = model['mt'][i]\n",
    "        vt_minus_1_weight, vt_minus_1_bias = model['vt'][i]\n",
    "        \n",
    "        # Calculating exponentially moving averages.\n",
    "        mt_weight = beta_1 * mt_minus_1_weight + one_minus_beta_1 * grad_weight\n",
    "        mt_bias = beta_1 * mt_minus_1_bias + one_minus_beta_1 * grad_bias\n",
    "        \n",
    "        vt_weight = beta_2 * vt_minus_1_weight + one_minus_beta_2 * grad_weight * grad_weight\n",
    "        vt_bias = beta_2 * vt_minus_1_bias + one_minus_beta_2 * grad_bias * grad_bias\n",
    "\n",
    "        # Bias correction of our moving averages.\n",
    "        mt_hat_weight = mt_weight / one_minus_beta_1t\n",
    "        mt_hat_bias = mt_bias / one_minus_beta_1t\n",
    "        vt_hat_weight = vt_weight / one_minus_beta_2t\n",
    "        vt_hat_bias = vt_bias / one_minus_beta_2t\n",
    "\n",
    "        # Calculate change in weights.\n",
    "        deltat_weight = mt_hat_weight / (np.sqrt(vt_hat_weight) + epsilon)\n",
    "        deltat_bias = mt_hat_bias / (np.sqrt(vt_hat_bias) + epsilon)\n",
    "        \n",
    "        # Update weights.\n",
    "        weight = weight + (lr * deltat_weight)\n",
    "        bias = bias + (lr * deltat_bias)\n",
    "\n",
    "        # Write to model.\n",
    "        model['layers'][i] = (weight, bias)\n",
    "        model['mt'][i] = (mt_weight, mt_bias)\n",
    "        model['vt'][i] = (vt_weight, vt_bias)\n",
    "\n",
    "    \n",
    "    model['t'] = t\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.logspace(-3, -5, num=3)\n",
    "\n",
    "layer_sizes_list = [\n",
    "    [30, 15],\n",
    "    [40, 16],\n",
    "    [20, 8, 3],\n",
    "    [35, 20, 4],\n",
    "    [40, 20, 10],\n",
    "    [50, 30, 8],\n",
    "    [60, 40, 15, 4],\n",
    "    [50, 30, 15, 8],\n",
    "]\n",
    "\n",
    "batch_sizes = [int(b) for b in np.logspace(2, 4, num=3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently have 54 unique combinations of hyper parameters, which is too much to test in a reasonable amount of time. We will randomly sample 10 of those 54 hyper parameter settings to try out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that it is possible we could end up testing the same hyper parameter settings\n",
    "# multiple times. We won't correct for this.\n",
    "\n",
    "hyperparams = []\n",
    "\n",
    "for i in range(10):\n",
    "    lr = learning_rates[int(math.floor(len(learning_rates) * random()))]\n",
    "    layer_sizes = layer_sizes_list[int(math.floor(len(layer_sizes_list) * random()))]\n",
    "    batch_size = batch_sizes[int(math.floor(len(batch_sizes) * random()))]\n",
    "\n",
    "    hyperparams.append({'lr': lr, 'layer_sizes': layer_sizes, 'batch_size': batch_size})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layer_sizes):\n",
    "    model = { 'layers': xavier_initialization(2, layer_sizes) }\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, lr, batch_size, epochs=1000, logs=True):\n",
    "\n",
    "    m = train_data.shape[1]\n",
    "\n",
    "    train_errors = []\n",
    "\n",
    "    reset_Adam(model)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for (batch_i, batch_start) in enumerate(range(0, m, batch_size)):\n",
    "            batch_X = train_data[:, batch_start:min(m, batch_start+batch_size)]\n",
    "            batch_Y = train_labels[batch_start:min(m, batch_start+batch_size)]\n",
    "\n",
    "            forward(model, batch_X)\n",
    "            backward(model, batch_Y)\n",
    "            gradient_clipping(model, threshold=1.0)\n",
    "            step_Adam(model, lr=lr)\n",
    "            # step_SGD(model, lr=lr)\n",
    "\n",
    "        if logs and i % 10 == 0:\n",
    "            # Turn off gradient checking while we calculate training\n",
    "            # and test loss.\n",
    "            no_grad_check(model)\n",
    "\n",
    "            train_output = forward(model, train_data)\n",
    "            train_error = binary_cross_entropy_loss(train_output, train_labels)\n",
    "            train_errors.append(train_error)\n",
    "\n",
    "            print(f'Train Error {train_error}')\n",
    "            \n",
    "            l2_norm = 0\n",
    "            max_grad = 0\n",
    "            min_grad = float('inf')\n",
    "\n",
    "            for grad in model['grads']:\n",
    "                weight, bias = grad\n",
    "                l2_norm += np.sum(weight * weight)\n",
    "                l2_norm += np.sum(bias * bias)\n",
    "\n",
    "                max_grad = max(max_grad, np.amax(np.abs(weight)))\n",
    "                min_grad = min(min_grad, np.amin(np.abs(weight)))\n",
    "\n",
    "            l2_norm = math.sqrt(l2_norm)\n",
    "\n",
    "            # Checking the overall squared gradient magnitude to look for\n",
    "            # any issues with vanishing / exploding gradients.\n",
    "            print(f'Grad Mag={l2_norm}, Grad Min={min_grad}, Grad Max={max_grad}')\n",
    "            \n",
    "            max_mt = 0\n",
    "            min_mt = float('inf')\n",
    "\n",
    "            for mt in model['mt']:\n",
    "                mt_weight, mt_bias = mt\n",
    "                max_mt = max(max_mt, np.amax(np.abs(mt_weight)))\n",
    "                min_mt = min(min_mt, np.amin(np.abs(mt_weight)))\n",
    "                \n",
    "            max_vt = 0\n",
    "            min_vt = float('inf')\n",
    "            \n",
    "            for vt in model['vt']:\n",
    "                vt_weight, vt_bias = vt\n",
    "                max_vt = max(max_vt, np.amax(np.abs(vt_weight)))\n",
    "                min_vt = min(min_vt, np.amin(np.abs(vt_weight)))\n",
    "                \n",
    "            print(f'Min m_t={min_mt}, Max m_t={max_mt}')\n",
    "            print(f'Min v_t={min_vt}, Max v_t={max_vt}')\n",
    "\n",
    "            # Turn gradient checking back on before we start a new epoch.\n",
    "            grad_check(model)\n",
    "\n",
    "    if logs:\n",
    "        return train_errors\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 / 10\n",
      "lr=0.001, layer_sizes=[50, 30, 15, 8], batch_size=100\n",
      "Train Error 0.30586779078258597\n",
      "Grad Mag=0.17657784032187682, Grad Min=0.0, Grad Max=0.1757113073010012\n",
      "Min m_t=0.0, Max m_t=0.02027560129800833\n",
      "Min v_t=0.0, Max v_t=0.08683013378316567\n",
      "Train Error 0.307700449387822\n",
      "Grad Mag=0.5467126514516789, Grad Min=0.0, Grad Max=0.5466093894129131\n",
      "Min m_t=0.0, Max m_t=0.005634589691209148\n",
      "Min v_t=0.0, Max v_t=0.6586265837660972\n",
      "Train Error 0.3077056896521126\n",
      "Grad Mag=0.5482206680215768, Grad Min=0.0, Grad Max=0.5481173357735396\n",
      "Min m_t=0.0, Max m_t=0.00545098848030709\n",
      "Min v_t=0.0, Max v_t=0.6592341913050419\n",
      "Train Error 0.3077068476692363\n",
      "Grad Mag=0.5485389596252849, Grad Min=0.0, Grad Max=0.5484356636478293\n",
      "Min m_t=0.0, Max m_t=0.005421730845489504\n",
      "Min v_t=0.0, Max v_t=0.6593755606433782\n",
      "Train Error 0.3077075402510245\n",
      "Grad Mag=0.5487302656056803, Grad Min=0.0, Grad Max=0.5486269915116632\n",
      "Min m_t=0.0, Max m_t=0.005404210574877999\n",
      "Min v_t=0.0, Max v_t=0.6594603298734214\n",
      "Train Error 0.3077080360734156\n",
      "Grad Mag=0.5488677114518847, Grad Min=0.0, Grad Max=0.5487644530784584\n",
      "Min m_t=0.0, Max m_t=0.005391635699376764\n",
      "Min v_t=0.0, Max v_t=0.659521164819649\n",
      "Train Error 0.30770842258109654\n",
      "Grad Mag=0.5489751407135681, Grad Min=0.0, Grad Max=0.5488718946209589\n",
      "Min m_t=0.0, Max m_t=0.005381808464625222\n",
      "Min v_t=0.0, Max v_t=0.6595686874919634\n",
      "Train Error 0.30770873937998805\n",
      "Grad Mag=0.5490633870725021, Grad Min=0.0, Grad Max=0.5489601510627222\n",
      "Min m_t=0.0, Max m_t=0.005373736118249227\n",
      "Min v_t=0.0, Max v_t=0.659607711973064\n",
      "Train Error 0.3077090078181341\n",
      "Grad Mag=0.5491383001127974, Grad Min=0.0, Grad Max=0.5490350726578205\n",
      "Min m_t=0.0, Max m_t=0.0053668829583151875\n",
      "Min v_t=0.0, Max v_t=0.6596408322615327\n",
      "Train Error 0.30770924071707983\n",
      "Grad Mag=0.5492034036058643, Grad Min=0.0, Grad Max=0.5491001835808531\n",
      "Min m_t=0.0, Max m_t=0.005360934373929531\n",
      "Min v_t=0.0, Max v_t=0.6596696093155962\n",
      "Train Error 0.3077094463948167\n",
      "Grad Mag=0.5492609834813189, Grad Min=0.0, Grad Max=0.5491577700235558\n",
      "Min m_t=0.0, Max m_t=0.005355681098413292\n",
      "Min v_t=0.0, Max v_t=0.6596950563780077\n",
      "Train Error 0.30770963056154466\n",
      "Grad Mag=0.549312605648314, Grad Min=0.0, Grad Max=0.5492093980755092\n",
      "Min m_t=0.0, Max m_t=0.005350971021688765\n",
      "Min v_t=0.0, Max v_t=0.6597178643346726\n",
      "Train Error 0.3077097972981816\n",
      "Grad Mag=0.549359394366438, Grad Min=0.0, Grad Max=0.5492561921244217\n",
      "Min m_t=0.0, Max m_t=0.005346702472024553\n",
      "Min v_t=0.0, Max v_t=0.6597385216852681\n",
      "Train Error 0.30770994961759224\n",
      "Grad Mag=0.549402181972033, Grad Min=0.0, Grad Max=0.5492989846022999\n",
      "Min m_t=0.0, Max m_t=0.005342798638683664\n",
      "Min v_t=0.0, Max v_t=0.659757406918376\n",
      "Train Error 0.30771008981626063\n",
      "Grad Mag=0.5494416020546942, Grad Min=0.0, Grad Max=0.5493384091719765\n",
      "Min m_t=0.0, Max m_t=0.005339201458615168\n",
      "Min v_t=0.0, Max v_t=0.6597748050125469\n",
      "Train Error 0.30771021968240064\n",
      "Grad Mag=0.5494781487680155, Grad Min=0.0, Grad Max=0.5493749600436715\n",
      "Min m_t=0.0, Max m_t=0.005335865950679378\n",
      "Min v_t=0.0, Max v_t=0.6597909342605943\n",
      "Train Error 0.30771034063407826\n",
      "Grad Mag=0.5495122147286687, Grad Min=0.0, Grad Max=0.549409029879034\n",
      "Min m_t=0.0, Max m_t=0.005332756364242873\n",
      "Min v_t=0.0, Max v_t=0.659805968210947\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7aafa39ebe95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layer_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mno_grad_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-d9286d892acd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, train_labels, lr, batch_size, epochs, logs)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mgradient_clipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a6445f3f9217>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlinear_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "valid_errors = []\n",
    "train_times = []\n",
    "\n",
    "data = train_data\n",
    "labels = train_labels\n",
    "\n",
    "# For each set of hyper parameters, create and train a new model.\n",
    "# Record the trained model with the corresponding validation error.\n",
    "for (i, hyperparam) in enumerate(hyperparams):\n",
    "    print(f'Training model {i + 1} / {len(hyperparams)}')\n",
    "    print(f'lr={hyperparam[\"lr\"]}, layer_sizes={hyperparam[\"layer_sizes\"]}, batch_size={hyperparam[\"batch_size\"]}')\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    model = create_model(hyperparam['layer_sizes'])\n",
    "\n",
    "    train_model(model, data, labels, lr=hyperparam['lr'], batch_size=hyperparam['batch_size'])\n",
    "\n",
    "    no_grad_check(model)\n",
    "\n",
    "    valid_output = forward(model, valid_data)\n",
    "    valid_error = binary_cross_entropy_loss(valid_output, valid_labels)\n",
    "\n",
    "    grad_check(model)\n",
    "    \n",
    "    models.append(model)\n",
    "    valid_errors.append(valid_error)\n",
    "\n",
    "    end_time = time()\n",
    "\n",
    "    print(f'Model took {(end_time - start_time) / 60:0.2f}m to train.')\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
